{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa\n",
    "#!pip install tensorflow\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e839217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting up Pyspark in Jupyter Notebook\n",
    "import findspark\n",
    "findspark.init('C:\\spark-3.3.1-bin-hadoop2')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7284b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c900e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data as a pandas dataframe\n",
    "metadata = pd.read_csv('C:/Users/Brianrod/Downloads/music1/IA/train.csv')\n",
    "#metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa49f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function that will extract features from each wave file of each foler\n",
    "file_name='C:/Users/Brianrod/Downloads/music1/IA/data_out'\n",
    "\n",
    "def features_extractor(file):\n",
    "    #load the file (audio)\n",
    "    #We are able to load and read these files using the Librosa package\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    #we extract mfcc\n",
    "    #mfcc is one of the 2 features we extarct as we slow down the rate of the audio to capture more information from each\n",
    "    #frame of the audio file\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    #for our second set of features we take the mean of the array using the previous feature. \n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c09d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19905it [09:48, 33.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#Now we use the features_extractor function and append that value into an array\n",
    "extracted_features=[]\n",
    "#tqdm will help us see the progress the loop has made and it can take up to 10 minutes.\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    try:\n",
    "        #Through the file_name variable we are able to create a path between the .wav files and the information contained about\n",
    "        #the .wav file in the csv file. This helps us know what genre each .wav file will be.\n",
    "        file_name = os.path.join(os.path.abspath('C:/Users/Brianrod/Downloads/music1/IA/data_out'),str(row[\"genre_id\"])+'/',str(row[\"filename\"]))\n",
    "        final_class_labels=row[\"genre\"]\n",
    "        data=features_extractor(file_name)\n",
    "        extracted_features.append([data,final_class_labels])\n",
    "    #I have place the below line so that the loop does not end when it faces a file that does not match as a 'wav' file.\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dc405d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-220.76562, 90.60733, 49.78978, 26.039112, 5....</td>\n",
       "      <td>Instrumental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[18.86783, 80.36447, 0.5729405, 23.20239, -0.7...</td>\n",
       "      <td>Punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-290.6577, 83.498055, -42.749413, 21.640993, ...</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-262.08475, 144.38524, -108.97106, -26.358757...</td>\n",
       "      <td>Old-Time / Historic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[15.768597, 72.60664, 4.0164847, 32.805832, 2....</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19891</th>\n",
       "      <td>[-64.83869, 46.36941, 8.45531, 45.98196, -0.35...</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>[-170.57887, 106.53604, 42.701595, 28.565674, ...</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>[-12.067158, 46.283924, 0.009649797, 29.335272...</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>[-129.28217, 82.20686, 18.308973, 53.467686, 1...</td>\n",
       "      <td>Punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>[-289.23605, 147.76265, 30.262993, 26.133278, ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19896 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature                genre\n",
       "0      [-220.76562, 90.60733, 49.78978, 26.039112, 5....         Instrumental\n",
       "1      [18.86783, 80.36447, 0.5729405, 23.20239, -0.7...                 Punk\n",
       "2      [-290.6577, 83.498055, -42.749413, 21.640993, ...                 Folk\n",
       "3      [-262.08475, 144.38524, -108.97106, -26.358757...  Old-Time / Historic\n",
       "4      [15.768597, 72.60664, 4.0164847, 32.805832, 2....                 Rock\n",
       "...                                                  ...                  ...\n",
       "19891  [-64.83869, 46.36941, 8.45531, 45.98196, -0.35...           Electronic\n",
       "19892  [-170.57887, 106.53604, 42.701595, 28.565674, ...              Hip-Hop\n",
       "19893  [-12.067158, 46.283924, 0.009649797, 29.335272...              Hip-Hop\n",
       "19894  [-129.28217, 82.20686, 18.308973, 53.467686, 1...                 Punk\n",
       "19895  [-289.23605, 147.76265, 30.262993, 26.133278, ...                 Rock\n",
       "\n",
       "[19896 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','genre'])\n",
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ede2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to convert the pandas dataframe into a spark dataframe to being using pyspark.\n",
    "spark = SparkSession.builder.appName(\"pandas to spark\").getOrCreate()\n",
    "col = [f'Value{i}' for i in range(len(extracted_features_df['feature'][0]))]\n",
    "df3 = extracted_features_df.feature.apply(pd.Series)\n",
    "df3.columns = col\n",
    "df3['genre'] = extracted_features_df['genre']\n",
    "df_sp = spark.createDataFrame(df3)\n",
    "#type(df_sp)\n",
    "#df_sp.show()\n",
    "#df_sp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b99b9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': {0: array([-220.76562   ,   90.60733   ,   49.78978   ,   26.039112  ,\n",
       "            5.5850687 ,   19.75965   ,  -16.241432  ,   10.575141  ,\n",
       "            0.7575977 ,   -5.1816783 ,    0.651591  ,   -3.3306482 ,\n",
       "           -1.895248  ,    2.7754571 ,    1.3352169 ,   -6.0598707 ,\n",
       "            4.5441833 ,   -5.583124  ,    3.8036451 ,    8.072292  ,\n",
       "           -3.9814079 ,   10.748935  ,   -8.948521  ,   -4.6125026 ,\n",
       "           -3.6112123 ,   -5.2807927 ,   -0.6133772 ,   -6.272189  ,\n",
       "           -2.1429634 ,   -2.1390417 ,   -0.7451536 ,   -6.8895445 ,\n",
       "           -2.2823555 ,   -7.6757054 ,   -3.4441836 ,   -3.561907  ,\n",
       "           -2.9988928 ,    2.256279  ,   -0.57180977,   -1.6650013 ],\n",
       "        dtype=float32)},\n",
       " 'genre': {0: 'Instrumental'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The features column stores the data as an array and we will need to tranform it into a vector to be able to use it.\n",
    "extracted_features_df[0:1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "569a21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              vector|\n",
      "+--------------------+\n",
      "|[-220.765625,90.6...|\n",
      "|[18.8678302764892...|\n",
      "|[-290.65771484375...|\n",
      "|[-262.08474731445...|\n",
      "|[15.7685966491699...|\n",
      "|[-304.86917114257...|\n",
      "|[-120.08622741699...|\n",
      "|[-137.44456481933...|\n",
      "|[-70.225433349609...|\n",
      "|[-241.76977539062...|\n",
      "|[-308.45782470703...|\n",
      "|[-151.09271240234...|\n",
      "|[-88.015144348144...|\n",
      "|[-206.65264892578...|\n",
      "|[-323.08123779296...|\n",
      "|[-19.575395584106...|\n",
      "|[-242.74482727050...|\n",
      "|[-172.43980407714...|\n",
      "|[-154.71791076660...|\n",
      "|[-41.144653320312...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Specifying input columns and the output column where they will be combined which is 'vector'\n",
    "assembler = VectorAssembler(inputCols=['Value0', 'Value1','Value2','Value3','Value4','Value5','Value6','Value7','Value8',\n",
    "'Value9','Value10','Value11','Value12','Value13','Value14','Value15','Value16','Value17','Value18','Value19','Value20',\n",
    "'Value21','Value22','Value23','Value24', 'Value25','Value26','Value27','Value28','Value29','Value30','Value31','Value32',\n",
    "'Value33','Value34','Value35','Value36','Value37','Value38','Value39'],\n",
    "                           outputCol='vector')\n",
    "\n",
    "#Transforming the data into a vector\n",
    "final_data = assembler.transform(df_sp)\n",
    "\n",
    "#Viewing the vector\n",
    "final_data.select('vector').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f48eb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to remove the 'genre' as it is a string and will give errors when building the pipeline as it will only take numeric data.\n",
    "genre_df = df_sp.select('genre').distinct().toPandas()\n",
    "genre_df[\"genre_label\"] = genre_df.index + 1\n",
    "genere_spark_df = spark.createDataFrame(genre_df)\n",
    "genre_labelled_df = df_sp.join(\n",
    "    genere_spark_df,\n",
    "    \"genre\"\n",
    ").drop(\"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f54a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will build the pipeline to generate predictions of what the genre of music it will be.\n",
    "#For this pipeline I have used RandomForestClassifier which works better with many target variable, in this case 'genres'\n",
    "forestclassifier = RandomForestClassifier(\n",
    "    featuresCol='vector',\n",
    "    labelCol='genre_label'\n",
    ")\n",
    "\n",
    "forest_pipeline = Pipeline(\n",
    "    stages= [assembler, forestclassifier]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4b3f14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+--------------------+----------+\n",
      "|              vector|genre_label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------+--------------------+--------------------+----------+\n",
      "|[-220.765625,90.6...|          3|[0.0,0.8219636575...|[0.0,0.0410981828...|      15.0|\n",
      "|[-308.45782470703...|          3|[0.0,0.7811105867...|[0.0,0.0390555293...|      11.0|\n",
      "|[-323.08123779296...|          3|[0.0,0.5351607894...|[0.0,0.0267580394...|       3.0|\n",
      "|[-251.44256591796...|          3|[0.0,0.9394591462...|[0.0,0.0469729573...|      11.0|\n",
      "|[-383.65261840820...|          3|[0.0,0.6563661210...|[0.0,0.0328183060...|      15.0|\n",
      "|[-285.96405029296...|          3|[0.0,0.5798971386...|[0.0,0.0289948569...|      15.0|\n",
      "|[-143.62411499023...|          3|[0.0,0.7904316344...|[0.0,0.0395215817...|      15.0|\n",
      "|[-85.137138366699...|          3|[0.0,0.8070518119...|[0.0,0.0403525905...|       4.0|\n",
      "|[-196.28053283691...|          3|[0.0,0.6371877569...|[0.0,0.0318593878...|      15.0|\n",
      "|[-180.95129394531...|          3|[0.0,1.0049414621...|[0.0,0.0502470731...|       7.0|\n",
      "|[-537.60827636718...|          3|[0.0,0.5673089948...|[0.0,0.0283654497...|       3.0|\n",
      "|[-129.29640197753...|          3|[0.0,0.7544424120...|[0.0,0.0377221206...|      11.0|\n",
      "|[-167.74966430664...|          3|[0.0,0.9588656328...|[0.0,0.0479432816...|      15.0|\n",
      "|[-256.83239746093...|          3|[0.0,1.1684175150...|[0.0,0.0584208757...|      11.0|\n",
      "|[-138.42581176757...|          3|[0.0,1.3848731400...|[0.0,0.0692436570...|       4.0|\n",
      "|[-176.87876892089...|          3|[0.0,0.7277292965...|[0.0,0.0363864648...|       7.0|\n",
      "|[-326.57540893554...|          3|[0.0,1.2718760393...|[0.0,0.0635938019...|       7.0|\n",
      "|[-347.40597534179...|          3|[0.0,0.9088282901...|[0.0,0.0454414145...|      15.0|\n",
      "|[-64.209693908691...|          3|[0.0,0.7962447940...|[0.0,0.0398122397...|      15.0|\n",
      "|[-282.24951171875...|          3|[0.0,0.7579142697...|[0.0,0.0378957134...|       3.0|\n",
      "+--------------------+-----------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the pipeline for the trained data\n",
    "model = forest_pipeline.fit(genre_labelled_df)\n",
    "# transform the data\n",
    "sample_data_train = model.transform(genre_labelled_df)\n",
    "\n",
    "# view some of the columns generated\n",
    "sample_data_train.select('vector', 'genre_label', 'rawPrediction', 'probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7c02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
